{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import compute_class_weight\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir(\"Cropped/UTKFace\"):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        row_data = [os.path.join(\"Cropped/UTKFace\", filename)]\n",
    "        filename = filename.split(\"_\")\n",
    "        if len(filename) > 3:\n",
    "            # TODO REPLACE INT WITH NAME\n",
    "            row_data.append(filename[2]) # 3rd integer represents race\n",
    "            data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "df_image = pd.DataFrame(data, columns = [\"filename\", \"Race\"])\n",
    "\n",
    "df_image = df_image[df_image[\"Race\"] != \"4\"]\n",
    "\n",
    "train, test = train_test_split(df_image, stratify = df_image[\"Race\"], test_size=0.2)\n",
    "\n",
    "# train = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255).flow_from_dataframe(\n",
    "#     dataframe = train,\n",
    "#     x_col = \"filename\",\n",
    "#     y_col = \"Race\",\n",
    "#     class_mode = \"categorical\",\n",
    "#     target_size = (200, 200),\n",
    "#     fill_mode = \"nearest\",\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "train = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255,\n",
    "                                                        fill_mode=\"nearest\").flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (200, 200),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255).flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    fill_mode = \"nearest\",\n",
    "    target_size=(200, 200)\n",
    ")\n",
    "    \n",
    "# batch = next(train)\n",
    "# a = np.array(batch[0])\n",
    "\n",
    "# img = Image.fromarray(a[0].astype('uint8'), \"RGB\")\n",
    "# img.save(f\"test.png\")\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "0    0.457820\n",
       "1    0.205606\n",
       "3    0.180575\n",
       "2    0.155999\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image[\"Race\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54606569, 1.21591913, 1.60257717, 1.38446541])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_class_weight(\n",
    "    \"balanced\", \n",
    "    classes = np.array([\"0\", \"1\", \"2\", \"3\"]),\n",
    "    y = df_image[\"Race\"])\n",
    "\n",
    "# compute_class_weight(\n",
    "#     \"balanced\", \n",
    "#     classes = np.array([\"0\", \"1\"]),\n",
    "#     y = df_image[\"Race\"])\n",
    "# tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "551/551 [==============================] - 15s 26ms/step - loss: 4.5628 - accuracy: 0.2150 - val_loss: 1.3885 - val_accuracy: 0.2055\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.1999 - val_loss: 1.3833 - val_accuracy: 0.4579\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3941 - accuracy: 0.2632 - val_loss: 1.3820 - val_accuracy: 0.4579\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.4028 - accuracy: 0.4057 - val_loss: 1.3937 - val_accuracy: 0.1806\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3867 - accuracy: 0.2120 - val_loss: 1.3863 - val_accuracy: 0.1560\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3868 - accuracy: 0.2123 - val_loss: 1.3848 - val_accuracy: 0.4579\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.2143 - val_loss: 1.3826 - val_accuracy: 0.4579\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2868 - val_loss: 1.3882 - val_accuracy: 0.1560\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2313 - val_loss: 1.3869 - val_accuracy: 0.1806\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2204 - val_loss: 1.3829 - val_accuracy: 0.4579\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.2886 - val_loss: 1.3862 - val_accuracy: 0.1806\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2010 - val_loss: 1.3835 - val_accuracy: 0.2055\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2486 - val_loss: 1.3875 - val_accuracy: 0.1560\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.1833 - val_loss: 1.3830 - val_accuracy: 0.4579\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 13s 24ms/step - loss: 1.3865 - accuracy: 0.3103 - val_loss: 1.3880 - val_accuracy: 0.1806\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2388 - val_loss: 1.3900 - val_accuracy: 0.1560\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.1964 - val_loss: 1.3877 - val_accuracy: 0.1806\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2124 - val_loss: 1.3871 - val_accuracy: 0.1806\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 14s 24ms/step - loss: 1.3865 - accuracy: 0.2377 - val_loss: 1.3881 - val_accuracy: 0.1806\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 13s 24ms/step - loss: 1.3865 - accuracy: 0.2200 - val_loss: 1.3860 - val_accuracy: 0.1560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263ba23ffd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(200, 200, 3)))\n",
    "model.add(keras.layers.Dense(512, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(256, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "model.compile(loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"], optimizer=keras.optimizers.Adam())\n",
    "model.fit(train,\n",
    "          class_weight={0:0.54606569 , 1:1.21591913, 2:1.60257717, 3:1.38446541},\n",
    "          validation_data = test,\n",
    "          epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mlp_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "551/551 [==============================] - 69s 122ms/step - loss: 1.1742 - accuracy: 0.5225 - val_loss: 0.8590 - val_accuracy: 0.6852\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 64s 115ms/step - loss: 0.7716 - accuracy: 0.6463 - val_loss: 0.7035 - val_accuracy: 0.7340\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 59s 107ms/step - loss: 0.6601 - accuracy: 0.6918 - val_loss: 0.6391 - val_accuracy: 0.7836\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 58s 106ms/step - loss: 0.6187 - accuracy: 0.7073 - val_loss: 0.6253 - val_accuracy: 0.7974\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 58s 106ms/step - loss: 0.5531 - accuracy: 0.7357 - val_loss: 0.5417 - val_accuracy: 0.8235\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 58s 105ms/step - loss: 0.5057 - accuracy: 0.7612 - val_loss: 0.6760 - val_accuracy: 0.7699\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 58s 105ms/step - loss: 0.4633 - accuracy: 0.7870 - val_loss: 0.5220 - val_accuracy: 0.8238\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 58s 105ms/step - loss: 0.4221 - accuracy: 0.8089 - val_loss: 0.5691 - val_accuracy: 0.8060\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 59s 108ms/step - loss: 0.3958 - accuracy: 0.8174 - val_loss: 0.5700 - val_accuracy: 0.8101\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 58s 105ms/step - loss: 0.3743 - accuracy: 0.8300 - val_loss: 0.5784 - val_accuracy: 0.8160\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 58s 106ms/step - loss: 0.3585 - accuracy: 0.8422 - val_loss: 0.7122 - val_accuracy: 0.7854\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 58s 106ms/step - loss: 0.3267 - accuracy: 0.8533 - val_loss: 0.7355 - val_accuracy: 0.7213\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 58s 106ms/step - loss: 0.3237 - accuracy: 0.8597 - val_loss: 0.8550 - val_accuracy: 0.8228\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2851 - accuracy: 0.8746 - val_loss: 0.7059 - val_accuracy: 0.8337\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2718 - accuracy: 0.8829 - val_loss: 0.6572 - val_accuracy: 0.8465\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2552 - accuracy: 0.8857 - val_loss: 0.6370 - val_accuracy: 0.8179\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2511 - accuracy: 0.8871 - val_loss: 0.6879 - val_accuracy: 0.8460\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2392 - accuracy: 0.8935 - val_loss: 0.6630 - val_accuracy: 0.8406\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2470 - accuracy: 0.8893 - val_loss: 0.9165 - val_accuracy: 0.7436\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.2242 - accuracy: 0.8948 - val_loss: 0.6978 - val_accuracy: 0.8385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26362c3f9d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (5, 5), padding = \"same\", input_shape=(200, 200, 3), activation = \"relu\"))\n",
    "model.add(keras.layers.Conv2D(32, (5, 5), padding = \"same\", activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPool2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPool2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPool2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"], optimizer=keras.optimizers.Adam())\n",
    "model.fit(train,\n",
    "          validation_data = test,\n",
    "          class_weight={0:0.54606569, 1:1.21591913 , 2:1.60257717, 3:1.38446541},\n",
    "          batch_size = 64,\n",
    "          epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9998045e-01 1.5736923e-10 1.3597108e-10 1.9519108e-05]]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\n",
    "    r\"C:\\Users\\Allen\\Downloads\\IMG_0791.jpg\"\n",
    ")\n",
    "\n",
    "img = img.resize((200, 200))\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "predicted = model.predict(img_array)\n",
    "# print(np.argmax(predicted, axis = 1)[0])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "model = tf.keras.models.load_model(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\FacialRecognitionRacialBias\\cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
