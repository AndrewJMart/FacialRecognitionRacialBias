{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import gc\n",
    "from keras import backend\n",
    "import graphviz\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir(\"Cropped/UTKFace\"):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        row_data = [os.path.join(\"Cropped/UTKFace\", filename)]\n",
    "        filename = filename.split(\"_\")\n",
    "        if len(filename) > 3:\n",
    "            row_data.append(filename[2]) # 3rd integer represents race\n",
    "            data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.DataFrame(data, columns = [\"filename\", \"Race\"])\n",
    "\n",
    "df_image = df_image[df_image[\"Race\"] != \"4\"]\n",
    "\n",
    "train, test = train_test_split(df_image, stratify = df_image[\"Race\"], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race\n",
       "0    0.457820\n",
       "1    0.205606\n",
       "3    0.180575\n",
       "2    0.155999\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image[\"Race\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54606569, 1.21591913, 1.60257717, 1.38446541])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_class_weight(\n",
    "    \"balanced\", \n",
    "    classes = np.array([\"0\", \"1\", \"2\", \"3\"]),\n",
    "    y = df_image[\"Race\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "551/551 [==============================] - 16s 28ms/step - loss: 4.7593 - accuracy: 0.1899 - val_loss: 1.3865 - val_accuracy: 0.1828\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3929 - accuracy: 0.1948 - val_loss: 1.3893 - val_accuracy: 0.2055\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3871 - accuracy: 0.2232 - val_loss: 1.3873 - val_accuracy: 0.1560\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2354 - val_loss: 1.3904 - val_accuracy: 0.2055\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3867 - accuracy: 0.2418 - val_loss: 1.3900 - val_accuracy: 0.2055\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3867 - accuracy: 0.2170 - val_loss: 1.3888 - val_accuracy: 0.1560\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2437 - val_loss: 1.3872 - val_accuracy: 0.2055\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2443 - val_loss: 1.3837 - val_accuracy: 0.4579\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.3122 - val_loss: 1.3905 - val_accuracy: 0.1806\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2074 - val_loss: 1.3874 - val_accuracy: 0.1560\n",
      "138/138 [==============================] - 3s 20ms/step\n",
      "[{0: 0.0, 2: 100.0, 1: 0.0, 3: 0.0}]\n",
      "[0.18989211 0.1947757  0.22322544 0.23543441 0.24179444 0.21703577\n",
      " 0.24372515 0.24429302 0.31220898 0.20738217]\n",
      "[0.18282989 0.20554167 0.15602998 0.20554167 0.20554167 0.15602998\n",
      " 0.20554167 0.45786965 0.18055871 0.15602998]\n",
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 4.7170 - accuracy: 0.2095 - val_loss: 1.3881 - val_accuracy: 0.1806\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3896 - accuracy: 0.3399 - val_loss: 1.3938 - val_accuracy: 0.1806\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2019 - val_loss: 1.3910 - val_accuracy: 0.2053\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.2319 - val_loss: 1.3891 - val_accuracy: 0.2053\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 14s 24ms/step - loss: 1.3906 - accuracy: 0.2513 - val_loss: 1.3878 - val_accuracy: 0.1806\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3867 - accuracy: 0.2401 - val_loss: 1.3881 - val_accuracy: 0.2053\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2627 - val_loss: 1.3930 - val_accuracy: 0.1560\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.1984 - val_loss: 1.3826 - val_accuracy: 0.4579\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2696 - val_loss: 1.3918 - val_accuracy: 0.1560\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3866 - accuracy: 0.1909 - val_loss: 1.3842 - val_accuracy: 0.1560\n",
      "138/138 [==============================] - 3s 20ms/step\n",
      "[{0: 0.0, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 0.1488095238095238, 2: 100.0, 1: 0.0, 3: 0.0}]\n",
      "[0.19968768 0.2673481  0.21254969 0.23367405 0.24653606 0.22859171\n",
      " 0.2532084  0.2213515  0.29091425 0.19914822]\n",
      "[0.1816943  0.19305019 0.18067227 0.20542812 0.19305019 0.18067227\n",
      " 0.18078583 0.45786965 0.16829435 0.15602998]\n",
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "551/551 [==============================] - 15s 26ms/step - loss: 4.4638 - accuracy: 0.2260 - val_loss: 1.3871 - val_accuracy: 0.1660\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3869 - accuracy: 0.1928 - val_loss: 1.3834 - val_accuracy: 0.2058\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3867 - accuracy: 0.2154 - val_loss: 1.3888 - val_accuracy: 0.1806\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.2058 - val_loss: 1.3870 - val_accuracy: 0.1806\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3868 - accuracy: 0.2730 - val_loss: 1.3886 - val_accuracy: 0.2058\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3864 - accuracy: 0.2553 - val_loss: 1.3899 - val_accuracy: 0.2058\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.1980 - val_loss: 1.3850 - val_accuracy: 0.4581\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3866 - accuracy: 0.2404 - val_loss: 1.3883 - val_accuracy: 0.1556\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3866 - accuracy: 0.2045 - val_loss: 1.3837 - val_accuracy: 0.4579\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.2421 - val_loss: 1.3833 - val_accuracy: 0.4579\n",
      "138/138 [==============================] - 3s 20ms/step\n",
      "[{0: 0.0, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 0.1488095238095238, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 100.0, 2: 0.0, 1: 0.11037527593818984, 3: 0.0}]\n",
      "[0.20844218 0.24249479 0.21349612 0.22438009 0.25536627 0.23749764\n",
      " 0.23480976 0.22771153 0.26210486 0.21347719]\n",
      "[0.17647059 0.19728973 0.18063442 0.19713831 0.19728973 0.18903778\n",
      " 0.2732228  0.35710501 0.26481945 0.25664321]\n",
      "Found 17611 validated image filenames belonging to 4 classes.\n",
      "Found 4402 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "551/551 [==============================] - 14s 24ms/step - loss: 4.7599 - accuracy: 0.1907 - val_loss: 1.3894 - val_accuracy: 0.1806\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3892 - accuracy: 0.2233 - val_loss: 1.3885 - val_accuracy: 0.1806\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2204 - val_loss: 1.3894 - val_accuracy: 0.1806\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.1869 - val_loss: 1.3836 - val_accuracy: 0.4577\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2582 - val_loss: 1.3843 - val_accuracy: 0.4577\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2960 - val_loss: 1.3873 - val_accuracy: 0.1561\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2028 - val_loss: 1.3850 - val_accuracy: 0.4577\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.2325 - val_loss: 1.3870 - val_accuracy: 0.1561\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.2301 - val_loss: 1.3870 - val_accuracy: 0.1561\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3864 - accuracy: 0.2196 - val_loss: 1.3887 - val_accuracy: 0.1561\n",
      "138/138 [==============================] - 3s 20ms/step\n",
      "[{0: 0.0, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 0.1488095238095238, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 100.0, 2: 0.0, 1: 0.11037527593818984, 3: 0.0}, {2: 100.0, 0: 0.0, 1: 0.0, 3: 0.0}]\n",
      "[0.2040149  0.23768848 0.21522969 0.21501722 0.25608662 0.25211108\n",
      " 0.22681427 0.22890073 0.25409951 0.21500256]\n",
      "[0.17750287 0.19311723 0.18062575 0.26229035 0.26240391 0.18079469\n",
      " 0.31935372 0.30684511 0.23763094 0.23149876]\n",
      "Found 17611 validated image filenames belonging to 4 classes.\n",
      "Found 4402 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "551/551 [==============================] - 15s 26ms/step - loss: 3.7127 - accuracy: 0.2168 - val_loss: 1.3845 - val_accuracy: 0.4580\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3871 - accuracy: 0.2617 - val_loss: 1.3862 - val_accuracy: 0.2054\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 14s 25ms/step - loss: 1.3865 - accuracy: 0.2302 - val_loss: 1.3842 - val_accuracy: 0.4580\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.2837 - val_loss: 1.3850 - val_accuracy: 0.4577\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3864 - accuracy: 0.1888 - val_loss: 1.3851 - val_accuracy: 0.4575\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.3652 - val_loss: 1.3893 - val_accuracy: 0.1806\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3866 - accuracy: 0.2247 - val_loss: 1.3889 - val_accuracy: 0.1806\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3865 - accuracy: 0.2467 - val_loss: 1.3908 - val_accuracy: 0.1556\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3864 - accuracy: 0.2502 - val_loss: 1.3892 - val_accuracy: 0.1556\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 14s 26ms/step - loss: 1.3864 - accuracy: 0.2194 - val_loss: 1.3824 - val_accuracy: 0.4577\n",
      "138/138 [==============================] - 3s 20ms/step\n",
      "[{0: 0.0, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 0.1488095238095238, 2: 100.0, 1: 0.0, 3: 0.0}, {0: 100.0, 2: 0.0, 1: 0.11037527593818984, 3: 0.0}, {2: 100.0, 0: 0.0, 1: 0.0, 3: 0.0}, {0: 100.0, 1: 0.0, 3: 0.0, 2: 0.0}]\n",
      "[0.20657118 0.24249307 0.21822316 0.22875105 0.24262978 0.27473412\n",
      " 0.22638924 0.23245339 0.25331652 0.21588371]\n",
      "[0.23359703 0.19556602 0.23609533 0.30138158 0.30142699 0.1807557\n",
      " 0.29160292 0.27659831 0.22122697 0.2767483 ]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "per_class_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(list(skf.split(X = df_image[\"filename\"], y = df_image[\"Race\"]))):\n",
    "    backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    train_df = df_image.iloc[train_index]\n",
    "    validation_df = df_image.iloc[val_index]\n",
    "\n",
    "    train = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255,\n",
    "                                                        fill_mode=\"nearest\").flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (200, 200),\n",
    "        )\n",
    "    test = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255).flow_from_dataframe(\n",
    "    dataframe = validation_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    fill_mode = \"nearest\",\n",
    "    target_size=(200, 200))\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(200, 200, 3)))\n",
    "    model.add(keras.layers.Dense(512, activation = \"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(256, activation = \"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "    model.compile(loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"], optimizer=keras.optimizers.Adam())\n",
    "    history = model.fit(train,\n",
    "            class_weight={0:0.54606569 , 1:1.21591913, 2:1.60257717, 3:1.38446541},\n",
    "            validation_data = test,\n",
    "            epochs = 10)\n",
    "\n",
    "    test.reset()\n",
    "    validation_predictions = np.argmax(model.predict(test), axis = -1)\n",
    "    validation_true = np.array(test.classes)\n",
    "    train_scores.append(history.history[\"accuracy\"])\n",
    "    val_scores.append(history.history[\"val_accuracy\"])\n",
    "\n",
    "    accuracy_per_class_temp = {}\n",
    "\n",
    "    class_dict = dict(Counter(test.classes))\n",
    "    for index, total in class_dict.items():\n",
    "        class_predict = validation_predictions[validation_true == index]\n",
    "        class_true = validation_true[validation_true == index]\n",
    "        correct_predictions = np.sum(class_predict == class_true)\n",
    "\n",
    "\n",
    "        percent_correct = (correct_predictions / total) * 100\n",
    "\n",
    "        accuracy_per_class_temp[index] = percent_correct\n",
    "\n",
    "    per_class_scores.append(accuracy_per_class_temp)\n",
    "    print(per_class_scores)\n",
    "\n",
    "    per_fold_train = np.mean(train_scores, axis = 0)\n",
    "    print(per_fold_train)\n",
    "    per_fold_validation = np.mean(val_scores, axis = 0)\n",
    "    print(per_fold_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20657118, 0.24249307, 0.21822316, 0.22875105, 0.24262978,\n",
       "       0.27473412, 0.22638924, 0.23245339, 0.25331652, 0.21588371])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_fold_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = pd.DataFrame({\"class\" : per_class_scores}) \n",
    "class_data.to_csv(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\class_scores_for_mlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_data = pd.DataFrame({\"Train\": per_fold_train, \"Validation\": per_fold_validation}) \n",
    "fold_data.to_csv(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\train_validation_for_mlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mlp_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "551/551 [==============================] - 85s 153ms/step - loss: 1.6791 - accuracy: 0.3215 - val_loss: 1.3713 - val_accuracy: 0.2126\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 1.2761 - accuracy: 0.2864 - val_loss: 1.3011 - val_accuracy: 0.3175\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 1.1482 - accuracy: 0.3743 - val_loss: 1.0229 - val_accuracy: 0.5344\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 1.0286 - accuracy: 0.4365 - val_loss: 1.0892 - val_accuracy: 0.5442\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.9672 - accuracy: 0.4748 - val_loss: 0.8853 - val_accuracy: 0.6736\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.8797 - accuracy: 0.5491 - val_loss: 0.8483 - val_accuracy: 0.6952\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.8413 - accuracy: 0.5897 - val_loss: 0.7840 - val_accuracy: 0.7565\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.7735 - accuracy: 0.6332 - val_loss: 0.7671 - val_accuracy: 0.7345\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.6707 - accuracy: 0.6955 - val_loss: 0.6578 - val_accuracy: 0.7783\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.5769 - accuracy: 0.7602 - val_loss: 0.6295 - val_accuracy: 0.8069\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.5147 - accuracy: 0.7958 - val_loss: 0.5851 - val_accuracy: 0.8054\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.4705 - accuracy: 0.8127 - val_loss: 0.6593 - val_accuracy: 0.8092\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.4097 - accuracy: 0.8380 - val_loss: 0.6824 - val_accuracy: 0.8056\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3842 - accuracy: 0.8468 - val_loss: 0.5762 - val_accuracy: 0.8192\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3593 - accuracy: 0.8560 - val_loss: 0.7689 - val_accuracy: 0.8099\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3464 - accuracy: 0.8597 - val_loss: 0.7571 - val_accuracy: 0.7988\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3235 - accuracy: 0.8658 - val_loss: 0.7695 - val_accuracy: 0.7733\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3020 - accuracy: 0.8733 - val_loss: 0.6890 - val_accuracy: 0.8203\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.2935 - accuracy: 0.8786 - val_loss: 0.7586 - val_accuracy: 0.8383\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.2733 - accuracy: 0.8822 - val_loss: 0.6412 - val_accuracy: 0.8322\n",
      "138/138 [==============================] - 5s 36ms/step\n",
      "[{0: 43.79960317460318, 2: 15.138282387190685, 1: 18.121546961325965, 3: 22.138364779874216}]\n",
      "[0.32152185 0.28642815 0.37427598 0.43651333 0.47478706 0.54906303\n",
      " 0.58972174 0.63321978 0.6955139  0.76019305 0.79579782 0.81266326\n",
      " 0.83804655 0.84684837 0.85604769 0.85968202 0.86581486 0.87325382\n",
      " 0.87864852 0.88216925]\n",
      "[0.21258233 0.31751078 0.53440833 0.54417443 0.67363161 0.69520783\n",
      " 0.75652963 0.73449922 0.77833295 0.80694979 0.80535996 0.80922097\n",
      " 0.80558711 0.81921417 0.80990231 0.79877359 0.77333635 0.82034975\n",
      " 0.83829206 0.83215988]\n",
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "551/551 [==============================] - 66s 118ms/step - loss: 1.3048 - accuracy: 0.4786 - val_loss: 0.9460 - val_accuracy: 0.6312\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 65s 118ms/step - loss: 0.8289 - accuracy: 0.6252 - val_loss: 0.9485 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 64s 117ms/step - loss: 0.7175 - accuracy: 0.6700 - val_loss: 0.5352 - val_accuracy: 0.8047\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 65s 118ms/step - loss: 0.6232 - accuracy: 0.7027 - val_loss: 0.5929 - val_accuracy: 0.7917\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 65s 117ms/step - loss: 0.5741 - accuracy: 0.7305 - val_loss: 0.6396 - val_accuracy: 0.7663\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 64s 117ms/step - loss: 0.5052 - accuracy: 0.7800 - val_loss: 0.6181 - val_accuracy: 0.7702\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 65s 117ms/step - loss: 0.4481 - accuracy: 0.8094 - val_loss: 0.6398 - val_accuracy: 0.7983\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 64s 117ms/step - loss: 0.3955 - accuracy: 0.8278 - val_loss: 0.6735 - val_accuracy: 0.8119\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.3417 - accuracy: 0.8463 - val_loss: 0.6362 - val_accuracy: 0.7804\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.3204 - accuracy: 0.8538 - val_loss: 0.5374 - val_accuracy: 0.8219\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 64s 117ms/step - loss: 0.2761 - accuracy: 0.8724 - val_loss: 0.6202 - val_accuracy: 0.8092\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.2590 - accuracy: 0.8781 - val_loss: 0.6767 - val_accuracy: 0.7733\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 64s 117ms/step - loss: 0.2469 - accuracy: 0.8869 - val_loss: 0.7061 - val_accuracy: 0.8433\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.2362 - accuracy: 0.8909 - val_loss: 0.7139 - val_accuracy: 0.8276\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.7138 - val_accuracy: 0.8406\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.2043 - accuracy: 0.8992 - val_loss: 0.6680 - val_accuracy: 0.8156\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.2046 - accuracy: 0.8988 - val_loss: 0.7019 - val_accuracy: 0.8431\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 64s 115ms/step - loss: 0.1879 - accuracy: 0.9181 - val_loss: 0.9340 - val_accuracy: 0.7995\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 64s 115ms/step - loss: 0.1909 - accuracy: 0.9333 - val_loss: 0.7379 - val_accuracy: 0.8276\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 0.1777 - accuracy: 0.9384 - val_loss: 0.8633 - val_accuracy: 0.8401\n",
      "138/138 [==============================] - 5s 36ms/step\n",
      "[{0: 43.79960317460318, 2: 15.138282387190685, 1: 18.121546961325965, 3: 22.138364779874216}, {0: 40.625, 2: 16.73944687045124, 1: 23.425414364640883, 3: 17.61006289308176}]\n",
      "[0.40005678 0.45582056 0.52214652 0.56959115 0.60264054 0.66453719\n",
      " 0.69957411 0.73049405 0.77089721 0.80698466 0.83409995 0.84540033\n",
      " 0.86249289 0.86885291 0.87393525 0.8794435  0.88231117 0.89565587\n",
      " 0.90596253 0.91027826]\n",
      "[0.42187145 0.47694755 0.66954347 0.66795367 0.71996367 0.73268226\n",
      " 0.77742448 0.7732228  0.77935499 0.81444469 0.80729046 0.79127866\n",
      " 0.82443789 0.82341585 0.82523277 0.80717695 0.80819896 0.80990234\n",
      " 0.83295479 0.83613443]\n",
      "Found 17610 validated image filenames belonging to 4 classes.\n",
      "Found 4403 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 1.1705 - accuracy: 0.5479 - val_loss: 1.5837 - val_accuracy: 0.4236\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 0.7740 - accuracy: 0.6595 - val_loss: 19.2412 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 76s 138ms/step - loss: 0.6445 - accuracy: 0.7359 - val_loss: 0.5867 - val_accuracy: 0.7949\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 75s 137ms/step - loss: 0.5580 - accuracy: 0.7638 - val_loss: 0.6864 - val_accuracy: 0.7556\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 74s 135ms/step - loss: 0.4983 - accuracy: 0.7951 - val_loss: 0.5497 - val_accuracy: 0.8085\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 75s 136ms/step - loss: 0.4288 - accuracy: 0.8140 - val_loss: 0.5674 - val_accuracy: 0.8231\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 0.3771 - accuracy: 0.8355 - val_loss: 0.6086 - val_accuracy: 0.7945\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 75s 137ms/step - loss: 0.3544 - accuracy: 0.8424 - val_loss: 0.6144 - val_accuracy: 0.8097\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 0.3261 - accuracy: 0.8551 - val_loss: 0.8665 - val_accuracy: 0.7697\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 75s 137ms/step - loss: 0.2954 - accuracy: 0.8622 - val_loss: 0.7951 - val_accuracy: 0.7731\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 75s 136ms/step - loss: 0.2856 - accuracy: 0.8680 - val_loss: 0.5853 - val_accuracy: 0.8260\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 75s 135ms/step - loss: 0.2704 - accuracy: 0.8723 - val_loss: 0.7447 - val_accuracy: 0.8010\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 74s 135ms/step - loss: 0.2432 - accuracy: 0.8864 - val_loss: 0.9034 - val_accuracy: 0.7947\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 75s 136ms/step - loss: 0.2519 - accuracy: 0.8901 - val_loss: 0.6772 - val_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 76s 139ms/step - loss: 0.2280 - accuracy: 0.8978 - val_loss: 0.6702 - val_accuracy: 0.8408\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 0.2252 - accuracy: 0.9017 - val_loss: 0.6878 - val_accuracy: 0.8394\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 76s 138ms/step - loss: 0.2088 - accuracy: 0.9093 - val_loss: 0.7743 - val_accuracy: 0.8122\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 75s 136ms/step - loss: 0.2033 - accuracy: 0.9128 - val_loss: 0.6888 - val_accuracy: 0.8326\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 74s 135ms/step - loss: 0.1945 - accuracy: 0.9165 - val_loss: 0.8253 - val_accuracy: 0.8181\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 0.1930 - accuracy: 0.9183 - val_loss: 0.7301 - val_accuracy: 0.8129\n",
      "138/138 [==============================] - 5s 36ms/step\n",
      "[{0: 43.79960317460318, 2: 15.138282387190685, 1: 18.121546961325965, 3: 22.138364779874216}, {0: 40.625, 2: 16.73944687045124, 1: 23.425414364640883, 3: 17.61006289308176}, {0: 48.51190476190476, 2: 16.18075801749271, 1: 18.874172185430464, 3: 15.723270440251572}]\n",
      "[0.44934696 0.52371758 0.59339392 0.63433656 0.66679917 0.7143479\n",
      " 0.7448798  0.7678024  0.79897785 0.82538331 0.84539088 0.85438198\n",
      " 0.87047132 0.87592276 0.88188529 0.88686353 0.89131174 0.90136286\n",
      " 0.90946432 0.9129472 ]\n",
      "[0.42243924 0.38307215 0.71133318 0.69717618 0.74948899 0.76281323\n",
      " 0.78310243 0.78537361 0.77613749 0.80066621 0.81353621 0.79453403\n",
      " 0.8145204  0.81542887 0.83041865 0.81792718 0.80952382 0.81747293\n",
      " 0.82799606 0.82837458]\n",
      "Found 17611 validated image filenames belonging to 4 classes.\n",
      "Found 4402 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "551/551 [==============================] - 72s 129ms/step - loss: 1.4155 - accuracy: 0.3304 - val_loss: 1.0965 - val_accuracy: 0.4448\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 70s 128ms/step - loss: 1.0756 - accuracy: 0.3892 - val_loss: 1.5967 - val_accuracy: 0.4196\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 71s 129ms/step - loss: 1.0103 - accuracy: 0.4200 - val_loss: 1.3218 - val_accuracy: 0.4914\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 69s 126ms/step - loss: 0.8936 - accuracy: 0.4775 - val_loss: 0.9899 - val_accuracy: 0.5254\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 74s 134ms/step - loss: 0.8335 - accuracy: 0.5217 - val_loss: 0.9119 - val_accuracy: 0.6163\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 70s 126ms/step - loss: 0.7684 - accuracy: 0.5817 - val_loss: 0.7760 - val_accuracy: 0.6522\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 69s 125ms/step - loss: 0.7143 - accuracy: 0.6313 - val_loss: 0.8749 - val_accuracy: 0.6956\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 70s 127ms/step - loss: 0.6654 - accuracy: 0.6624 - val_loss: 1.2044 - val_accuracy: 0.6411\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 70s 126ms/step - loss: 0.6299 - accuracy: 0.6825 - val_loss: 0.7271 - val_accuracy: 0.6972\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 69s 125ms/step - loss: 0.5666 - accuracy: 0.7026 - val_loss: 0.6296 - val_accuracy: 0.7803\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 69s 125ms/step - loss: 0.4900 - accuracy: 0.7375 - val_loss: 0.6145 - val_accuracy: 0.8035\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 69s 125ms/step - loss: 0.4357 - accuracy: 0.8546 - val_loss: 0.6980 - val_accuracy: 0.8226\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 68s 123ms/step - loss: 0.4058 - accuracy: 0.8633 - val_loss: 0.6379 - val_accuracy: 0.8303\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 68s 124ms/step - loss: 0.3717 - accuracy: 0.8791 - val_loss: 0.6834 - val_accuracy: 0.8319\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 69s 124ms/step - loss: 0.3265 - accuracy: 0.8996 - val_loss: 0.6257 - val_accuracy: 0.8433\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 68s 124ms/step - loss: 0.3259 - accuracy: 0.9018 - val_loss: 0.7423 - val_accuracy: 0.8258\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 69s 124ms/step - loss: 0.3026 - accuracy: 0.9093 - val_loss: 0.6104 - val_accuracy: 0.8503\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 70s 126ms/step - loss: 0.2823 - accuracy: 0.9190 - val_loss: 0.7150 - val_accuracy: 0.8342\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 69s 124ms/step - loss: 0.2665 - accuracy: 0.9202 - val_loss: 0.6838 - val_accuracy: 0.8408\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 70s 126ms/step - loss: 0.2539 - accuracy: 0.9265 - val_loss: 0.7954 - val_accuracy: 0.8303\n",
      "138/138 [==============================] - 5s 36ms/step\n",
      "[{0: 43.79960317460318, 2: 15.138282387190685, 1: 18.121546961325965, 3: 22.138364779874216}, {0: 40.625, 2: 16.73944687045124, 1: 23.425414364640883, 3: 17.61006289308176}, {0: 48.51190476190476, 2: 16.18075801749271, 1: 18.874172185430464, 3: 15.723270440251572}, {0: 41.736972704714645, 2: 16.73944687045124, 1: 22.320441988950275, 3: 24.27672955974843}]\n",
      "[0.41960064 0.49008533 0.55005083 0.59512383 0.63052922 0.6811814\n",
      " 0.71647315 0.74145852 0.76985118 0.79469474 0.81841657 0.85443136\n",
      " 0.8686845  0.87671947 0.88631602 0.89060333 0.89581332 0.90577911\n",
      " 0.91213912 0.916327  ]\n",
      "[0.42802889 0.39219962 0.65634177 0.65424287 0.71619444 0.73516081\n",
      " 0.76122506 0.74929826 0.75639889 0.79558145 0.81102675 0.80154568\n",
      " 0.8184664  0.8195453  0.83362725 0.81988564 0.81971669 0.82164627\n",
      " 0.83118559 0.82885703]\n",
      "Found 17611 validated image filenames belonging to 4 classes.\n",
      "Found 4402 validated image filenames belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "551/551 [==============================] - 64s 114ms/step - loss: 1.4460 - accuracy: 0.2889 - val_loss: 1.2493 - val_accuracy: 0.5186\n",
      "Epoch 2/20\n",
      "551/551 [==============================] - 63s 114ms/step - loss: 1.2006 - accuracy: 0.4414 - val_loss: 1.1866 - val_accuracy: 0.5034\n",
      "Epoch 3/20\n",
      "551/551 [==============================] - 62s 113ms/step - loss: 1.1215 - accuracy: 0.3855 - val_loss: 1.1148 - val_accuracy: 0.3619\n",
      "Epoch 4/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 1.0682 - accuracy: 0.3819 - val_loss: 0.9915 - val_accuracy: 0.5111\n",
      "Epoch 5/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 1.0150 - accuracy: 0.4111 - val_loss: 1.0028 - val_accuracy: 0.4680\n",
      "Epoch 6/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.8897 - accuracy: 0.5518 - val_loss: 0.9493 - val_accuracy: 0.7001\n",
      "Epoch 7/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.7953 - accuracy: 0.7259 - val_loss: 0.8094 - val_accuracy: 0.7585\n",
      "Epoch 8/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.7027 - accuracy: 0.7666 - val_loss: 0.6939 - val_accuracy: 0.8062\n",
      "Epoch 9/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.6417 - accuracy: 0.7965 - val_loss: 0.8358 - val_accuracy: 0.7310\n",
      "Epoch 10/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.6117 - accuracy: 0.8065 - val_loss: 0.7075 - val_accuracy: 0.8119\n",
      "Epoch 11/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.5663 - accuracy: 0.8274 - val_loss: 0.6297 - val_accuracy: 0.8403\n",
      "Epoch 12/20\n",
      "551/551 [==============================] - 61s 111ms/step - loss: 0.5290 - accuracy: 0.8401 - val_loss: 0.6398 - val_accuracy: 0.8473\n",
      "Epoch 13/20\n",
      "551/551 [==============================] - 63s 115ms/step - loss: 0.4986 - accuracy: 0.8486 - val_loss: 0.6567 - val_accuracy: 0.8389\n",
      "Epoch 14/20\n",
      "551/551 [==============================] - 63s 114ms/step - loss: 0.4553 - accuracy: 0.8629 - val_loss: 0.6495 - val_accuracy: 0.8185\n",
      "Epoch 15/20\n",
      "551/551 [==============================] - 57s 104ms/step - loss: 0.4326 - accuracy: 0.8732 - val_loss: 0.6252 - val_accuracy: 0.8078\n",
      "Epoch 16/20\n",
      "551/551 [==============================] - 60s 108ms/step - loss: 0.4207 - accuracy: 0.8784 - val_loss: 21.6991 - val_accuracy: 0.2710\n",
      "Epoch 17/20\n",
      "551/551 [==============================] - 60s 109ms/step - loss: 0.3825 - accuracy: 0.8894 - val_loss: 0.6546 - val_accuracy: 0.8414\n",
      "Epoch 18/20\n",
      "551/551 [==============================] - 59s 108ms/step - loss: 0.3722 - accuracy: 0.8971 - val_loss: 0.7069 - val_accuracy: 0.7790\n",
      "Epoch 19/20\n",
      "551/551 [==============================] - 56s 101ms/step - loss: 0.3447 - accuracy: 0.9060 - val_loss: 0.6600 - val_accuracy: 0.8373\n",
      "Epoch 20/20\n",
      "551/551 [==============================] - 56s 102ms/step - loss: 0.3296 - accuracy: 0.9131 - val_loss: 0.6686 - val_accuracy: 0.8396\n",
      "138/138 [==============================] - 4s 26ms/step\n",
      "[{0: 43.79960317460318, 2: 15.138282387190685, 1: 18.121546961325965, 3: 22.138364779874216}, {0: 40.625, 2: 16.73944687045124, 1: 23.425414364640883, 3: 17.61006289308176}, {0: 48.51190476190476, 2: 16.18075801749271, 1: 18.874172185430464, 3: 15.723270440251572}, {0: 41.736972704714645, 2: 16.73944687045124, 1: 22.320441988950275, 3: 24.27672955974843}, {0: 44.516129032258064, 2: 14.119359534206696, 1: 24.30939226519337, 3: 17.48427672955975}]\n",
      "[0.39346258 0.48034264 0.5171402  0.55247179 0.58664472 0.6552966\n",
      " 0.71834915 0.74648008 0.77519046 0.79706407 0.82022073 0.85156507\n",
      " 0.86467106 0.8739609  0.88369366 0.88815696 0.89452811 0.90403389\n",
      " 0.91090486 0.91567473]\n",
      "[0.44614868 0.4144412  0.59744961 0.62562056 0.66654937 0.72815591\n",
      " 0.76068382 0.7606835  0.75132538 0.79884589 0.81688137 0.81070497\n",
      " 0.82256049 0.81933455 0.82846473 0.71011115 0.8240605  0.81310984\n",
      " 0.83241781 0.8310093 ]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "per_class_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(list(skf.split(X = df_image[\"filename\"], y = df_image[\"Race\"]))):\n",
    "    backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    train_df = df_image.iloc[train_index]\n",
    "    validation_df = df_image.iloc[val_index]\n",
    "\n",
    "    train = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255,\n",
    "                                                        fill_mode=\"nearest\").flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (200, 200),\n",
    "        )\n",
    "    test = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255).flow_from_dataframe(\n",
    "    dataframe = validation_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"Race\",\n",
    "    class_mode = \"categorical\",\n",
    "    fill_mode = \"nearest\",\n",
    "    target_size=(200, 200))\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (5, 5), padding = \"same\", input_shape=(200, 200, 3), activation = \"relu\"))\n",
    "    model.add(keras.layers.Conv2D(32, (5, 5), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(4, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"], optimizer=keras.optimizers.Adam())\n",
    "    history = model.fit(train,\n",
    "            validation_data = test,\n",
    "            class_weight={0:0.54606569, 1:1.21591913 , 2:1.60257717, 3:1.38446541},\n",
    "            batch_size = 64,\n",
    "            epochs = 20)\n",
    "\n",
    "    test.reset()\n",
    "    validation_predictions = np.argmax(model.predict(test), axis = -1)\n",
    "    validation_true = np.array(test.classes)\n",
    "    train_scores.append(history.history[\"accuracy\"])\n",
    "    val_scores.append(history.history[\"val_accuracy\"])\n",
    "\n",
    "    accuracy_per_class_temp = {}\n",
    "\n",
    "    class_dict = dict(Counter(test.classes))\n",
    "    for index, total in class_dict.items():\n",
    "        class_predict = validation_predictions[validation_true == index]\n",
    "        class_true = validation_true[validation_true == index]\n",
    "        correct_predictions = np.sum(class_predict == class_true)\n",
    "        percent_correct = (correct_predictions / total) * 100\n",
    "\n",
    "        accuracy_per_class_temp[index] = percent_correct\n",
    "\n",
    "    per_class_scores.append(accuracy_per_class_temp)\n",
    "    print(per_class_scores)\n",
    "\n",
    "    per_fold_train = np.mean(train_scores, axis = 0)\n",
    "    print(per_fold_train)\n",
    "    per_fold_validation = np.mean(val_scores, axis = 0)\n",
    "    print(per_fold_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = pd.DataFrame({\"class\" : per_class_scores}) \n",
    "class_data.to_csv(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\class_scores_for_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_data = pd.DataFrame({\"Train\": per_fold_train, \"Validation\": per_fold_validation}) \n",
    "fold_data.to_csv(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\train_validation_for_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9998045e-01 1.5736923e-10 1.3597108e-10 1.9519108e-05]]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\n",
    "    r\"C:\\Users\\Allen\\Downloads\\IMG_0791.jpg\"\n",
    ")\n",
    "\n",
    "img = img.resize((200, 200))\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "predicted = model.predict(img_array)\n",
    "# print(np.argmax(predicted, axis = 1)[0])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "model = tf.keras.models.load_model(r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\FacialRecognitionRacialBias\\cnn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file = r\"C:\\Users\\Allen\\Desktop\\Coding\\CSC 466\\model_cnn.png\", expand_nested = True,\n",
    "                          rankdir= \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
